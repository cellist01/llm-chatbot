import streamlit as st
import requests
from datetime import datetime
import json
import pandas as pd

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ìƒìˆ˜ ë° ê¸°ë³¸ê°’ ì •ì˜
MAX_MESSAGES = 50
API_TIMEOUT = 30
API_URL = "https://model.odyssey-ai.svc.cluster.local/v1/completions"

DEFAULT_PARAMS = {
    "max_tokens": 512,
    "temperature": 0.5,
    "top_p": 0.95,
    "presence_penalty": 0.0,
    "frequency_penalty": 0.0
}

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
    <style>
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .user-message {
        background-color: #e3f2fd;
        margin-left: 20%;
    }
    .assistant-message {
        background-color: #f5f5f5;
        margin-right: 20%;
    }
    .message-timestamp {
        color: #666;
        font-size: 0.8rem;
    }
    .debug-info {
        background-color: #fff3e0;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    </style>
    """, unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state['messages'] = []
if 'processing' not in st.session_state:
    st.session_state['processing'] = False
if 'parameters' not in st.session_state:
    st.session_state['parameters'] = DEFAULT_PARAMS.copy()

def create_prompt(user_input):
    """êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {user_input}

ë‹µë³€ì˜ ê·œì¹™:
1. ì •í™•í•œ ì •ë³´ë§Œ ì œê³µí•©ë‹ˆë‹¤.
2. ì•Œì§€ ëª»í•˜ëŠ” ë‚´ìš©ì€ "í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•©ë‹ˆë‹¤.
3. ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
4. ê´€ë ¨ ì •ë³´ë§Œ ì œê³µí•©ë‹ˆë‹¤.

ë‹µë³€:"""

def call_llm_api(prompt):
    """LLM API í˜¸ì¶œ"""
    try:
        structured_prompt = create_prompt(prompt)
        
        if DEBUG_MODE:
            st.write("êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸:", structured_prompt)
            st.write("í˜„ì¬ íŒŒë¼ë¯¸í„°:", st.session_state['parameters'])
        
        response = requests.post(
            API_URL,
            json={
                "model": "model",
                "prompt": structured_prompt,
                **st.session_state['parameters']
            },
            verify=False,
            timeout=API_TIMEOUT
        )
        
        if DEBUG_MODE:
            st.write("API ì‘ë‹µ ìƒíƒœ:", response.status_code)
        
        if response.status_code != 200:
            return f"API ì˜¤ë¥˜: {response.status_code}"
            
        result = response.json()
        
        if DEBUG_MODE:
            st.write("API ì‘ë‹µ:", result)
            
        if "choices" not in result or not result["choices"]:
            return "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        return result["choices"][0]["text"].strip()
        
    except Exception as e:
        return f"Error: {str(e)}"

# ë©”ì¸ í™”ë©´
st.title("AI ì±—ë´‡")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ì„¤ì •")
    
    # íŒŒë¼ë¯¸í„° ì„¤ì • ì„¹ì…˜
    st.subheader("ëª¨ë¸ íŒŒë¼ë¯¸í„°")
    with st.expander("ê³ ê¸‰ ì„¤ì •", expanded=False):
        # max_tokens ì„¤ì •
        st.session_state['parameters']['max_tokens'] = st.slider(
            "Maximum Tokens",
            min_value=50,
            max_value=1000,
            value=st.session_state['parameters'].get('max_tokens', DEFAULT_PARAMS['max_tokens']),
            step=50,
            help="ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ (ë” ê¸´ ì‘ë‹µì„ ì›í•  ê²½ìš° ì¦ê°€)"
        )

        # temperature ì„¤ì •
        st.session_state['parameters']['temperature'] = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state['parameters'].get('temperature', DEFAULT_PARAMS['temperature']),
            step=0.1,
            help="ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ì‘ë‹µ, ë‚®ì„ìˆ˜ë¡ ë” ì¼ê´€ëœ ì‘ë‹µ"
        )

        # top_p ì„¤ì •
        st.session_state['parameters']['top_p'] = st.slider(
            "Top P",
            min_value=0.1,
            max_value=1.0,
            value=st.session_state['parameters'].get('top_p', DEFAULT_PARAMS['top_p']),
            step=0.05,
            help="ë‹¤ìŒ í† í° ì„ íƒì‹œ ê³ ë ¤í•  í™•ë¥  ë¶„í¬ì˜ ìƒìœ„ ë¹„ìœ¨"
        )

        # presence_penalty ì„¤ì •
        st.session_state['parameters']['presence_penalty'] = st.slider(
            "Presence Penalty",
            min_value=-2.0,
            max_value=2.0,
            value=st.session_state['parameters'].get('presence_penalty', DEFAULT_PARAMS['presence_penalty']),
            step=0.1,
            help="ìƒˆë¡œìš´ ì£¼ì œ ë„ì… ê°•ë„ (ì–‘ìˆ˜: ìƒˆë¡œìš´ ì£¼ì œ ì„ í˜¸, ìŒìˆ˜: ê¸°ì¡´ ì£¼ì œ ìœ ì§€)"
        )

        # frequency_penalty ì„¤ì •
        st.session_state['parameters']['frequency_penalty'] = st.slider(
            "Frequency Penalty",
            min_value=-2.0,
            max_value=2.0,
            value=st.session_state['parameters'].get('frequency_penalty', DEFAULT_PARAMS['frequency_penalty']),
            step=0.1,
            help="ë‹¨ì–´ ë°˜ë³µ ì–µì œ ì •ë„ (ì–‘ìˆ˜: ë°˜ë³µ ì–µì œ, ìŒìˆ˜: ë°˜ë³µ í—ˆìš©)"
        )

        # íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”"):
            st.session_state['parameters'] = DEFAULT_PARAMS.copy()
            st.experimental_rerun()

    # í”„ë¦¬ì…‹ ì„¤ì •
    st.subheader("í”„ë¦¬ì…‹")
    preset = st.selectbox(
        "íŒŒë¼ë¯¸í„° í”„ë¦¬ì…‹",
        ["ê¸°ë³¸", "ì°½ì˜ì ", "ì •í™•ì„±", "ê°„ë‹¨ ì‘ë‹µ", "ìƒì„¸ ì„¤ëª…"],
        help="ë¯¸ë¦¬ ì •ì˜ëœ íŒŒë¼ë¯¸í„° ì„¤ì •"
    )

    # í”„ë¦¬ì…‹ ì„ íƒì‹œ íŒŒë¼ë¯¸í„° ìë™ ì„¤ì •
    if preset == "ì°½ì˜ì ":
        st.session_state['parameters'] = {
            "max_tokens": 750,
            "temperature": 0.8,
            "top_p": 0.9,
            "presence_penalty": 0.5,
            "frequency_penalty": 0.3
        }
    elif preset == "ì •í™•ì„±":
        st.session_state['parameters'] = {
            "max_tokens": 512,
            "temperature": 0.3,
            "top_p": 0.95,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0
        }
    elif preset == "ê°„ë‹¨ ì‘ë‹µ":
        st.session_state['parameters'] = {
            "max_tokens": 128,
            "temperature": 0.4,
            "top_p": 0.95,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.5
        }
    elif preset == "ìƒì„¸ ì„¤ëª…":
        st.session_state['parameters'] = {
            "max_tokens": 1000,
            "temperature": 0.6,
            "top_p": 0.9,
            "presence_penalty": 0.2,
            "frequency_penalty": 0.2
        }

    st.divider()

    # ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
    DEBUG_MODE = st.checkbox("ë””ë²„ê·¸ ëª¨ë“œ", value=False)
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state['messages'] = []
        st.rerun()
    
    # ëŒ€í™” ë‚´ë³´ë‚´ê¸°
    if st.session_state['messages']:
        df = pd.DataFrame(st.session_state['messages'])
        csv = df.to_csv(index=False)
        st.download_button(
            label="ëŒ€í™” ë‚´ì—­ ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )

# ì±„íŒ… ì´ë ¥ í‘œì‹œ
for message in st.session_state['messages']:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        st.caption(f"{message['timestamp']}")
        if DEBUG_MODE and "debug_info" in message:
            st.info(f"ë””ë²„ê·¸ ì •ë³´: {message['debug_info']}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    if not st.session_state['processing']:
        st.session_state['processing'] = True
        
        with st.chat_message("user"):
            st.markdown(prompt)
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            st.caption(timestamp)
        
        message_data = {
            "role": "user",
            "content": prompt,
            "timestamp": timestamp
        }
        
        if DEBUG_MODE:
            message_data["debug_info"] = {"input_length": len(prompt)}
        
        st.session_state['messages'].append(message_data)

        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = call_llm_api(prompt)
                st.markdown(response)
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                st.caption(timestamp)
        
        message_data = {
            "role": "assistant",
            "content": response,
            "timestamp": timestamp
        }
        
        if DEBUG_MODE:
            message_data["debug_info"] = {"response_length": len(response)}
        
        st.session_state['messages'].append(message_data)
        
        if len(st.session_state['messages']) > MAX_MESSAGES:
            st.session_state['messages'] = st.session_state['messages'][-MAX_MESSAGES:]
        
        st.session_state['processing'] = False
